{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbb01e1-0ff6-4c47-a855-b9ec20266e91",
   "metadata": {},
   "source": [
    "****Project Brief****\n",
    "Problem: Choice Overload. Users waste more time searching than reading because of decision paralysis and a \"winner-takes-all\" market.\n",
    "Solution: A context-aware engine that replaces popularity bias with situational matching (mood, time, environment e.g. bedtime, 10mins, long holiday/travelling).\n",
    "Goal: Reduce decision fatigue and unlock the \"Long Tail\" of publishing/giving niche books the spotlight while helping readers find the perfect book for their current moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c69502-0c20-4bf2-b180-a7bccfdc89ef",
   "metadata": {},
   "source": [
    "****Goodreads Webscraping****\n",
    "Book data required \n",
    "- Genre \n",
    "- Title \n",
    "- Author\n",
    "- Rating\n",
    "- Rating counts \n",
    "- Description \n",
    "- Page numbers \n",
    "- ISBN\n",
    "- Language \n",
    "- Published Year \n",
    "- Book Cover Image \n",
    "- Link to the book "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12d655-e7e7-4d69-a887-ada29e077333",
   "metadata": {},
   "source": [
    "****Open Library API***\n",
    "Identifiers: ISBN-13\n",
    "Physical Specs: Number of pages, physical dimensions, weight, and binding type (Hardcover, mass-market paperback, etc.).\n",
    "\n",
    "Publishing Info: Publisher name, specific publication date, and series name.\n",
    "\n",
    "Table of Contents: Often includes a full list of chapters (a feature many other APIs lack).\n",
    "\n",
    "3. The \"Author\" Layer\n",
    "Open Library treats authors as distinct entities with their own metadata.\n",
    "\n",
    "Biographical Data: Full name, birth/death dates, and a biography.\n",
    "\n",
    "Identifiers: Links to external authority files like VIAF, Wikidata, and Library of Congress ID.\n",
    "\n",
    "Photos: Portraits of the author when available.\n",
    "\n",
    "4. Digital & Community Data\n",
    "Because Open Library is part of the Internet Archive, it includes unique \"living\" data:\n",
    "\n",
    "Availability: Data on whether an eBook version is available to borrow, read online, or download.\n",
    "\n",
    "Community Activity: User-generated Reading Logs (Want to Read, Currently Reading, Have Read), public Book Lists, and user ratings.\n",
    "\n",
    "Revision History: Every single change made to a record is stored, meaning you can access previous \"versions\" of a book's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d572664f-9f18-432c-a399-7c9007ee5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1948c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Parsed JSON-LD fields ===\n",
      "title: The Hunger Games (The Hunger Games, #1)\n",
      "author: Suzanne Collins\n",
      "rating: 4.35\n",
      "rating_count: 9943052\n",
      "description: \n",
      "isbn: 9780439023481\n",
      "image: https://m.media-amazon.com/images/S/compressed.photo.goodreads.com/books/1586722975i/2767052.jpg\n",
      "url: \n"
     ]
    }
   ],
   "source": [
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/122.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def fetch_html(url: str) -> str:\n",
    "    r = requests.get(url, headers=HEADERS, timeout=25)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def extract_jsonld_blocks(html: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Goodreads 详情页通常会有 1~多个 JSON-LD script。\n",
    "    我们把能解析成 dict 的都收集起来。\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    blocks = []\n",
    "    for tag in soup.select('script[type=\"application/ld+json\"]'):\n",
    "        raw = tag.get_text(strip=True)\n",
    "        if not raw:\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(raw)\n",
    "            # 有时是 list，有时是 dict\n",
    "            if isinstance(data, list):\n",
    "                for item in data:\n",
    "                    if isinstance(item, dict):\n",
    "                        blocks.append(item)\n",
    "            elif isinstance(data, dict):\n",
    "                blocks.append(data)\n",
    "        except json.JSONDecodeError:\n",
    "            # 极少数页面 JSON-LD 可能含奇怪字符，跳过\n",
    "            continue\n",
    "    return blocks\n",
    "\n",
    "def pick_book_jsonld(blocks: list[dict]) -> dict | None:\n",
    "    \"\"\"\n",
    "    在 JSON-LD 里挑出最像“Book”的那一块。\n",
    "    常见：@type = \"Book\" 或 \"Product\"（里面也可能含 book 信息）\n",
    "    \"\"\"\n",
    "    for b in blocks:\n",
    "        t = b.get(\"@type\")\n",
    "        if isinstance(t, str) and t.lower() == \"book\":\n",
    "            return b\n",
    "\n",
    "    # 兜底：找包含 aggregateRating + author 的块\n",
    "    for b in blocks:\n",
    "        if \"aggregateRating\" in b and \"author\" in b and (\"name\" in b or \"url\" in b):\n",
    "            return b\n",
    "\n",
    "    return None\n",
    "\n",
    "def parse_book_from_jsonld(book: dict) -> dict:\n",
    "    \"\"\"\n",
    "    从 JSON-LD 提取你要的核心字段：\n",
    "    Title / Author / Rating / RatingCount / Description / ISBN / Image / URL\n",
    "    \"\"\"\n",
    "    title = book.get(\"name\", \"\") or \"\"\n",
    "    url = book.get(\"url\", \"\") or \"\"\n",
    "\n",
    "    # author 可能是 dict 或 list\n",
    "    author = \"\"\n",
    "    a = book.get(\"author\")\n",
    "    if isinstance(a, dict):\n",
    "        author = a.get(\"name\", \"\") or \"\"\n",
    "    elif isinstance(a, list) and a:\n",
    "        if isinstance(a[0], dict):\n",
    "            author = a[0].get(\"name\", \"\") or \"\"\n",
    "        elif isinstance(a[0], str):\n",
    "            author = a[0]\n",
    "\n",
    "    desc = book.get(\"description\", \"\") or \"\"\n",
    "    # 简单清理 description 里的多余空白\n",
    "    desc = re.sub(r\"\\s+\", \" \", desc).strip()\n",
    "\n",
    "    isbn = book.get(\"isbn\", \"\") or \"\"\n",
    "\n",
    "    image = book.get(\"image\", \"\") or \"\"\n",
    "    # image 有时是 list\n",
    "    if isinstance(image, list) and image:\n",
    "        image = image[0]\n",
    "\n",
    "    rating_value = \"\"\n",
    "    rating_count = \"\"\n",
    "    ar = book.get(\"aggregateRating\")\n",
    "    if isinstance(ar, dict):\n",
    "        rating_value = str(ar.get(\"ratingValue\", \"\") or \"\")\n",
    "        rating_count = str(ar.get(\"ratingCount\", \"\") or \"\")\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"author\": author,\n",
    "        \"rating\": rating_value,\n",
    "        \"rating_count\": rating_count,\n",
    "        \"description\": desc,\n",
    "        \"isbn\": isbn,\n",
    "        \"image\": image,\n",
    "        \"url\": url,\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # 你可以先用 The Hunger Games 这本书的详情页 URL（从榜单点进去复制）\n",
    "    test_url = \"https://www.goodreads.com/book/show/2767052-the-hunger-games\"\n",
    "    html = fetch_html(test_url)\n",
    "\n",
    "    blocks = extract_jsonld_blocks(html)\n",
    "    if not blocks:\n",
    "        raise RuntimeError(\"没有找到 JSON-LD script（application/ld+json）\")\n",
    "\n",
    "    book_block = pick_book_jsonld(blocks)\n",
    "    if not book_block:\n",
    "        raise RuntimeError(\"找到 JSON-LD，但没定位到 Book 的那一块\")\n",
    "\n",
    "    data = parse_book_from_jsonld(book_block)\n",
    "\n",
    "    print(\"\\n=== Parsed JSON-LD fields ===\")\n",
    "    for k, v in data.items():\n",
    "        if k == \"description\":\n",
    "            print(f\"{k}: {v[:160]}{'...' if len(v) > 160 else ''}\")\n",
    "        else:\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d52a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Full parsed fields ===\n",
      "title: The Hunger Games (The Hunger Games, #1)\n",
      "author: Suzanne Collins\n",
      "rating: 4.35\n",
      "rating_count: 9943052\n",
      "description: Winning means fame and fortune. Losing means certain death. The Hunger Games have begun. . . . In the ruins of a place once known as North America lies the nation of Panem, a shining Capitol surrounde...\n",
      "isbn: 9780439023481\n",
      "image: https://m.media-amazon.com/images/S/compressed.photo.goodreads.com/books/1586722975i/2767052.jpg\n",
      "url_from_jsonld: \n",
      "book_url: https://www.goodreads.com/book/show/2767052-the-hunger-games\n",
      "pages: 374\n",
      "published_year: 2008\n",
      "language: \n",
      "genres: ['Young Adult', 'Dystopia', 'Fiction', 'Fantasy', 'Science Fiction']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/122.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "YEAR_RE = re.compile(r\"\\b(18|19|20)\\d{2}\\b\")\n",
    "PAGES_RE = re.compile(r\"(\\d+)\\s+pages\", re.IGNORECASE)\n",
    "\n",
    "def fetch_html(url: str) -> str:\n",
    "    r = requests.get(url, headers=HEADERS, timeout=25)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def extract_jsonld_blocks(soup: BeautifulSoup) -> list[dict]:\n",
    "    blocks = []\n",
    "    for tag in soup.select('script[type=\"application/ld+json\"]'):\n",
    "        raw = tag.get_text(strip=True)\n",
    "        if not raw:\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(raw)\n",
    "            if isinstance(data, list):\n",
    "                blocks.extend([x for x in data if isinstance(x, dict)])\n",
    "            elif isinstance(data, dict):\n",
    "                blocks.append(data)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    return blocks\n",
    "\n",
    "def pick_book_jsonld(blocks: list[dict]) -> dict | None:\n",
    "    for b in blocks:\n",
    "        t = b.get(\"@type\")\n",
    "        if isinstance(t, str) and t.lower() == \"book\":\n",
    "            return b\n",
    "    for b in blocks:\n",
    "        if \"aggregateRating\" in b and \"author\" in b and (\"name\" in b or \"@id\" in b):\n",
    "            return b\n",
    "    return None\n",
    "\n",
    "def parse_from_jsonld(book: dict) -> dict:\n",
    "    title = book.get(\"name\", \"\") or \"\"\n",
    "\n",
    "    author = \"\"\n",
    "    a = book.get(\"author\")\n",
    "    if isinstance(a, dict):\n",
    "        author = a.get(\"name\", \"\") or \"\"\n",
    "    elif isinstance(a, list) and a:\n",
    "        if isinstance(a[0], dict):\n",
    "            author = a[0].get(\"name\", \"\") or \"\"\n",
    "        elif isinstance(a[0], str):\n",
    "            author = a[0]\n",
    "\n",
    "    desc = book.get(\"description\", \"\") or \"\"\n",
    "    desc = re.sub(r\"\\s+\", \" \", desc).strip()\n",
    "\n",
    "    isbn = book.get(\"isbn\", \"\") or \"\"\n",
    "\n",
    "    image = book.get(\"image\", \"\") or \"\"\n",
    "    if isinstance(image, list) and image:\n",
    "        image = image[0]\n",
    "\n",
    "    rating_value = \"\"\n",
    "    rating_count = \"\"\n",
    "    ar = book.get(\"aggregateRating\")\n",
    "    if isinstance(ar, dict):\n",
    "        rating_value = str(ar.get(\"ratingValue\", \"\") or \"\")\n",
    "        rating_count = str(ar.get(\"ratingCount\", \"\") or \"\")\n",
    "\n",
    "    # 有些 JSON-LD 没有 url，但可能有 @id\n",
    "    url = book.get(\"url\") or book.get(\"@id\") or \"\"\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"author\": author,\n",
    "        \"rating\": rating_value,\n",
    "        \"rating_count\": rating_count,\n",
    "        \"description\": desc,\n",
    "        \"isbn\": isbn,\n",
    "        \"image\": image,\n",
    "        \"url_from_jsonld\": url,\n",
    "    }\n",
    "\n",
    "def extract_description_html(soup: BeautifulSoup) -> str:\n",
    "    \"\"\"\n",
    "    JSON-LD 没有 description 时，从页面描述区块兜底。\n",
    "    Goodreads 老页面常见 #description，新页面可能是 data-testid。\n",
    "    \"\"\"\n",
    "    # 1) 老页面\n",
    "    node = soup.select_one(\"#description\")\n",
    "    if node:\n",
    "        text = node.get_text(\" \", strip=True)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        return text\n",
    "\n",
    "    # 2) 新页面（兜底：找包含 “Description” 的区域可能不稳定，这里尽量温和）\n",
    "    for cand in soup.select(\"[data-testid]\"):\n",
    "        if cand.get(\"data-testid\", \"\").lower() in {\"description\"}:\n",
    "            text = cand.get_text(\" \", strip=True)\n",
    "            text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "            if text:\n",
    "                return text\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def extract_pages(soup: BeautifulSoup) -> int | None:\n",
    "    \"\"\"\n",
    "    从页面里找类似 “374 pages” 的文本并提取数字。\n",
    "    \"\"\"\n",
    "    text = soup.get_text(\" \", strip=True)\n",
    "    m = PAGES_RE.search(text)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return int(m.group(1))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def extract_published_year(soup: BeautifulSoup) -> int | None:\n",
    "    \"\"\"\n",
    "    你截图里的 TruncatedContent_text--small 里有：\n",
    "    'October 14, 2008 by Scholastic Press'\n",
    "    我们提取其中的年份。\n",
    "    \"\"\"\n",
    "    # 先精准抓 TruncatedContent 的小文本\n",
    "    node = soup.select_one(\".TruncatedContent_text--small\")\n",
    "    if node:\n",
    "        s = node.get_text(\" \", strip=True)\n",
    "        m = YEAR_RE.search(s)\n",
    "        if m:\n",
    "            return int(m.group(0))\n",
    "\n",
    "    # 兜底：整页搜年份，但可能误命中（所以优先用上面的精准方式）\n",
    "    text = soup.get_text(\" \", strip=True)\n",
    "    m = YEAR_RE.search(text)\n",
    "    if m:\n",
    "        return int(m.group(0))\n",
    "    return None\n",
    "\n",
    "def extract_language(soup: BeautifulSoup) -> str:\n",
    "    \"\"\"\n",
    "    Language 在 TruncatedContent_text--small 里，\n",
    "    且通常是一个单词（English / Spanish / German）\n",
    "    \"\"\"\n",
    "    for div in soup.select(\"div.TruncatedContent_text--small\"):\n",
    "        text = div.get_text(strip=True)\n",
    "        # 语言通常是纯字母，且长度合理\n",
    "        if text.isalpha() and 3 <= len(text) <= 15:\n",
    "            return text\n",
    "    return \"\"\n",
    "\n",
    "def extract_genres(soup: BeautifulSoup, topk: int = 5) -> list[str]:\n",
    "    \"\"\"\n",
    "    Goodreads 新页面：\n",
    "    Genre 是 a.Button.Button--tag\n",
    "    文本在 span.Button__labelItem\n",
    "    \"\"\"\n",
    "    genres = []\n",
    "    for span in soup.select(\"a.Button.Button--tag span.Button__labelItem\"):\n",
    "        g = span.get_text(strip=True)\n",
    "        if g:\n",
    "            genres.append(g)\n",
    "\n",
    "    # 去重，保持顺序\n",
    "    genres = list(dict.fromkeys(genres))\n",
    "    return genres[:topk]\n",
    "\n",
    "def parse_full_book(book_url: str) -> dict:\n",
    "    html = fetch_html(book_url)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    blocks = extract_jsonld_blocks(soup)\n",
    "    book_json = pick_book_jsonld(blocks) if blocks else None\n",
    "    base = parse_from_jsonld(book_json) if book_json else {}\n",
    "\n",
    "    # 你的最终 Link to the book：直接用请求的 URL，最可靠\n",
    "    base[\"book_url\"] = book_url\n",
    "\n",
    "    # Description 兜底\n",
    "    if not base.get(\"description\"):\n",
    "        base[\"description\"] = extract_description_html(soup)\n",
    "\n",
    "    # Pages / Year / Language / Genres\n",
    "    base[\"pages\"] = extract_pages(soup)\n",
    "    base[\"published_year\"] = extract_published_year(soup)\n",
    "    base[\"language\"] = extract_language(soup)\n",
    "    base[\"genres\"] = extract_genres(soup, topk=5)\n",
    "\n",
    "    return base\n",
    "\n",
    "def main():\n",
    "    test_url = \"https://www.goodreads.com/book/show/2767052-the-hunger-games\"\n",
    "    data = parse_full_book(test_url)\n",
    "\n",
    "    print(\"\\n=== Full parsed fields ===\")\n",
    "    for k, v in data.items():\n",
    "        if k == \"description\":\n",
    "            print(f\"{k}: {v[:200]}{'...' if v and len(v) > 200 else ''}\")\n",
    "        else:\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_recommendation_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
